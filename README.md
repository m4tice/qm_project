# qm_project
Bicycle project crowd evaluation.

This repository is created for evaluating the quality and performance of a new crowd in the project Bicycle crowd evaluation.  

The directory 'main_scripts' contains the scripts used for different analyzing purposes:

* Task 1:
    * task_1a.py:analyze the annotators contributing to the dataset and create the *'annotators.csv'*.
    * task_1b.py: analyze the annotation time and create the *'annotation_time.csv'*.
    * task_1b_by_image.py: analyze annotation time grouped by images and create the *'annotation_time_by_image.csv'*.
    * task_1b_by_user.py: analyze annotation time grouped by users and create the *'annotation_time_by_user.csv'*.
    * task_1c.py: analyze the amount of results of each annotator and create the *'annotator_result_count.csv'*.
    * task_1d.py: analyze the  highly disagree questions and create the *'question_answers.csv'*, *'question_groups.csv'* and *'highly_disagree_group.csv'*.

* Task 2:
    * analyze the occurrence of samples with label 'cant_solve' and 'corrupt_data' marked as True.
 

The directory 'files' contains the csv

